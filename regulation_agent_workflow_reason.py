"""
ê·œì œ AI Agent ì„œë¹„ìŠ¤ - LangGraph Multi-Agent Workflow (ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”)
8ê°œì˜ Agentë¡œ êµ¬ì„±ëœ ê·œì œ ë¶„ì„ ì‹œìŠ¤í…œ

1. Analyzer Agent: ì‚¬ì—… ì •ë³´ ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
2. Search Agent: Tavily APIë¥¼ í†µí•œ ê·œì œ ì •ë³´ ê²€ìƒ‰
3. Classifier Agent: ê²€ìƒ‰ëœ ê·œì œ ë¶„ë¥˜ ë° ì ìš©ì„± íŒë‹¨
4. Prioritizer Agent: ê·œì œ ìš°ì„ ìˆœìœ„ ê²°ì • (HIGH/MEDIUM/LOW)
5. Checklist Generator Agent: ê·œì œë³„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± [ë³‘ë ¬]
6. Risk Assessment Agent: ë¯¸ì¤€ìˆ˜ ì‹œ ë¦¬ìŠ¤í¬ í‰ê°€ ë° ì™„í™” ë°©ì•ˆ ì œì‹œ [ë³‘ë ¬]
7. Planning Agent: ì²´í¬ë¦¬ìŠ¤íŠ¸ â†’ ì‹¤í–‰ ê³„íš ë³€í™˜ (ì˜ì¡´ì„±, íƒ€ì„ë¼ì¸, ë§ˆì¼ìŠ¤í†¤)
8. Report Generation Agent: ìµœì¢… í†µí•© ë³´ê³ ì„œ ìƒì„± (ê²½ì˜ì§„/ì‹¤ë¬´ì§„/ë²•ë¬´íŒ€ìš©)
"""

import re
import sys
import json
import time
from typing import List, Optional, Dict, Any, Iterable, Union
from typing_extensions import TypedDict
from datetime import datetime
from dotenv import load_dotenv
from enum import Enum
from markdown import markdown
from pathlib import Path
from weasyprint import HTML, CSS

from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langchain.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langsmith import Client

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LangSmith API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = Client()

# ============================================
# ë°ì´í„° ëª¨ë¸ ì •ì˜
# ============================================

class Priority(str, Enum):
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"


class Category(str, Enum):
    SAFETY_ENV = "ì•ˆì „/í™˜ê²½"
    PRODUCT_CERT = "ì œí’ˆ ì¸ì¦"
    FACTORY_OPS = "ê³µì¥ ìš´ì˜"


class BusinessInfo(TypedDict, total=False):
    """ì‚¬ì—… ì •ë³´ ë°ì´í„° êµ¬ì¡°"""
    industry: str
    product_name: str
    raw_materials: str
    processes: List[str]
    employee_count: int
    sales_channels: List[str]
    export_countries: List[str]


class EvidenceItem(TypedDict, total=False):
    """LLM ë‹µë³€ì— í¬í•¨ë˜ëŠ” ê·¼ê±°/ì¶œì²˜ ì •ë³´"""
    source_id: str                   # ê²€ìƒ‰ ê²°ê³¼ ì‹ë³„ì (ì˜ˆ: SRC-001)
    title: str                       # ë¬¸ì„œ ì œëª©
    url: str                         # ë¬¸ì„œ URL
    snippet: str                     # ë°œì·Œ ë‚´ìš© (ì›ë³¸, ìƒëµ ê°€ëŠ¥)
    justification: str               # LLMì´ ìƒì„±í•œ concise ìš”ì•½ (ìš°ì„  ì‚¬ìš©)


class Regulation(TypedDict):
    """ê·œì œ ì •ë³´ ë°ì´í„° êµ¬ì¡°"""
    id: str
    name: str
    category: str
    why_applicable: str
    authority: str
    priority: str
    key_requirements: List[str]
    reference_url: Optional[str]
    sources: List[EvidenceItem]


class ChecklistItem(TypedDict):
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª© ë°ì´í„° êµ¬ì¡°"""
    regulation_id: str          # ì—°ê²°ëœ ê·œì œ ID
    regulation_name: str        # ê·œì œëª…
    task_name: str              # ì‘ì—…ëª…
    responsible_dept: str       # ë‹´ë‹¹ ë¶€ì„œ
    deadline: str               # ë§ˆê° ê¸°í•œ (YYYY-MM-DD í˜•ì‹)
    method: List[str]           # ì‹¤í–‰ ë°©ë²• (ë‹¨ê³„ë³„)
    estimated_time: str         # ì†Œìš” ì‹œê°„
    priority: str               # ìš°ì„ ìˆœìœ„ (ìƒìœ„ ê·œì œì™€ ë™ì¼)
    status: str                 # ìƒíƒœ (pending/in_progress/completed)
    evidence: List[EvidenceItem]


class Milestone(TypedDict):
    """ë§ˆì¼ìŠ¤í†¤ ë°ì´í„° êµ¬ì¡°"""
    name: str                           # ë§ˆì¼ìŠ¤í†¤ëª…
    deadline: str                       # ë§ˆê°ì¼ (ì˜ˆ: "1ê°œì›” ë‚´")
    tasks: List[str]                    # í¬í•¨ëœ ì‘ì—… IDë“¤
    completion_criteria: str            # ì™„ë£Œ ê¸°ì¤€


class ExecutionPlan(TypedDict):
    """ì‹¤í–‰ ê³„íš ë°ì´í„° êµ¬ì¡°"""
    plan_id: str                        # ê³„íš ID
    regulation_id: str                  # ì—°ê²°ëœ ê·œì œ ID
    regulation_name: str                # ê·œì œëª…
    checklist_items: List[str]          # ì—°ê²°ëœ ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª© IDë“¤
    timeline: str                       # ì˜ˆìƒ ì†Œìš” ê¸°ê°„ (ì˜ˆ: "3ê°œì›”")
    start_date: str                     # ì‹œì‘ ì‹œì  (ì˜ˆ: "ì¦‰ì‹œ", "ê³µì¥ë“±ë¡ í›„")
    milestones: List[Milestone]         # ë§ˆì¼ìŠ¤í†¤ ëª©ë¡
    dependencies: Dict[str, List[str]]  # ì„ í–‰ ì‘ì—… ì˜ì¡´ì„± (ì‘ì—…ID: [ì„ í–‰ì‘ì—…IDë“¤])
    parallel_tasks: List[List[str]]     # ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì—… ê·¸ë£¹
    critical_path: List[str]            # í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤ (ê°€ì¥ ê¸´ ê²½ë¡œ)
    evidence: List[EvidenceItem]


class FinalReport(TypedDict):
    """ìµœì¢… ë³´ê³ ì„œ ë°ì´í„° êµ¬ì¡°"""
    executive_summary: str              # ê²½ì˜ì§„ìš© ìš”ì•½ (ë§ˆí¬ë‹¤ìš´)
    detailed_report: str                # ì‹¤ë¬´ì§„ìš© ìƒì„¸ ë³´ê³ ì„œ (ë§ˆí¬ë‹¤ìš´)
    legal_report: str                   # ë²•ë¬´íŒ€ìš© ê·œì œ ìƒì„¸ (ë§ˆí¬ë‹¤ìš´)
    key_insights: List[str]             # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (3-5ê°œ)
    action_items: List[Dict[str, Any]]  # ì¦‰ì‹œ ì¡°ì¹˜ í•­ëª©
    risk_highlights: List[str]          # ì£¼ìš” ë¦¬ìŠ¤í¬ í•˜ì´ë¼ì´íŠ¸
    next_steps: List[str]               # ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­
    full_markdown: str                  # í†µí•© ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ (ì „ì²´)
    report_pdf_path: str                # PDF ì €ì¥ ê²½ë¡œ
    citations: List[EvidenceItem]       # ì „ì²´ ë³´ê³ ì„œì— í¬í•¨ëœ ì£¼ìš” ì¶œì²˜


class RiskItem(TypedDict):
    """ë¦¬ìŠ¤í¬ í•­ëª© ë°ì´í„° êµ¬ì¡°"""
    regulation_id: str          # ê·œì œ ID
    regulation_name: str        # ê·œì œëª…
    penalty_amount: str         # ë²Œê¸ˆì•¡
    penalty_type: str           # ë²Œì¹™ ìœ í˜• (ë²Œê¸ˆ/ì§•ì—­/ê³¼íƒœë£Œ)
    business_impact: str        # ì‚¬ì—… ì˜í–¥ (ì˜ì—…ì •ì§€/ì¸í—ˆê°€ ì·¨ì†Œ ë“±)
    risk_score: float           # ë¦¬ìŠ¤í¬ ì ìˆ˜ (0-10)
    past_cases: List[str]       # ê³¼ê±° ì²˜ë²Œ ì‚¬ë¡€
    mitigation: str             # ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆ
    evidence: List[EvidenceItem]


class RiskAssessment(TypedDict):
    """ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°"""
    total_risk_score: float             # ì „ì²´ ë¦¬ìŠ¤í¬ ì ìˆ˜ (0-10)
    high_risk_items: List[RiskItem]     # ê³ ìœ„í—˜ í•­ëª© (ì ìˆ˜ 7.0 ì´ìƒ)
    risk_matrix: Dict[str, Any]         # ë¦¬ìŠ¤í¬ ë§¤íŠ¸ë¦­ìŠ¤
    recommendations: List[str]          # ê¶Œì¥ ì‚¬í•­


class AgentState(TypedDict, total=False):
    """LangGraph State - Agent ê°„ ë°ì´í„° ì „ë‹¬"""
    # ê¸°ì¡´ í•„ë“œ
    business_info: BusinessInfo
    keywords: List[str]
    search_results: List[Dict[str, Any]]
    regulations: List[Regulation]
    final_output: Dict[str, Any]

    # Agent ê²°ê³¼ í•„ë“œ
    checklists: List[ChecklistItem]     # ì²´í¬ë¦¬ìŠ¤íŠ¸ ëª©ë¡
    execution_plans: List[ExecutionPlan]  # ì‹¤í–‰ ê³„íš (Planning Agent)
    risk_assessment: RiskAssessment     # ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼
    final_report: FinalReport           # ìµœì¢… ë³´ê³ ì„œ (Report Generation Agent)


# ============================================
# Helper í•¨ìˆ˜ë“¤
# ============================================

def _build_tavily_tool(max_results: int = 8, search_depth: str = "basic") -> TavilySearch:
    """TavilySearch ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        return TavilySearch(
            max_results=max_results,
            include_answer=True,
            include_raw_content=False,
            search_depth=search_depth,
            include_domains=["go.kr", "or.kr", "law.go.kr", "korea.kr"]
        )
    except Exception as exc:
        raise RuntimeError(
            "TavilySearch ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ 'TAVILY_API_KEY'ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        ) from exc


def _extract_results(payload: Any) -> List[Dict[str, Any]]:
    """Tavily API ì‘ë‹µì—ì„œ ê²°ê³¼ ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if isinstance(payload, dict) and "results" in payload:
        return payload.get("results", []) or []
    if isinstance(payload, dict) and {"title", "url"}.issubset(payload.keys()):
        return [payload]
    if isinstance(payload, list):
        return payload
    return []


def _truncate(text: str, limit: int = 300) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ê¸¸ì´ë¡œ ìë¦…ë‹ˆë‹¤."""
    if len(text) <= limit:
        return text
    return text[: limit - 3] + "..."


def _merge_evidence(evidence_lists: List[List[EvidenceItem]]) -> List[EvidenceItem]:
    """ì—¬ëŸ¬ Evidence ëª©ë¡ì„ ë³‘í•©í•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤."""
    merged: List[EvidenceItem] = []
    seen: set = set()
    for items in evidence_lists:
        for item in items or []:
            key = (item.get("source_id"), item.get("url"))
            if key in seen:
                continue
            seen.add(key)
            merged.append({
                "source_id": item.get("source_id", ""),
                "title": item.get("title", ""),
                "url": item.get("url", ""),
                "snippet": item.get("snippet", "")
            })
    return merged


def _normalize_evidence_payload(
    raw_evidence: Union[str, Dict[str, Any], Iterable[Any], None],
    source_lookup: Dict[str, Dict[str, Any]]
) -> List[EvidenceItem]:
    """LLMì´ ë°˜í™˜í•œ evidence í•„ë“œë¥¼ í‘œì¤€ EvidenceItem ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    normalized: List[EvidenceItem] = []
    if not raw_evidence:
        return normalized

    if isinstance(raw_evidence, dict):
        raw_iterable = [raw_evidence]
    elif isinstance(raw_evidence, str):
        raw_iterable = [raw_evidence]
    elif isinstance(raw_evidence, Iterable):
        raw_iterable = list(raw_evidence)
    else:
        raw_iterable = [raw_evidence]

    for entry in raw_iterable:
        if isinstance(entry, dict):
            src_id = entry.get("source_id") or ""
            justification_text = entry.get("justification") or entry.get("excerpt") or ""
        else:
            text = str(entry)
            match = re.match(r"(SRC-\d+)", text.strip())
            src_id = match.group(1) if match else ""
            justification_text = text

        source_meta = source_lookup.get(src_id, {}) if src_id else {}
        # snippetì€ ì›ë³¸ ìœ ì§€ (fallbackìš©), justificationì€ LLM ìš”ì•½ (ìš°ì„  ì‚¬ìš©)
        normalized.append({
            "source_id": src_id,
            "title": source_meta.get("title", ""),
            "url": source_meta.get("url", ""),
            "snippet": source_meta.get("snippet", "")[:300],  # ì›ë³¸ snippet (fallback)
            "justification": justification_text  # LLMì´ ìƒì„±í•œ ìš”ì•½ (ìƒëµ ì—†ìŒ)
        })

    return normalized


def _ensure_dict_list(payload: Any) -> List[Dict[str, Any]]:
    """LLM ì‘ë‹µ(payload)ì„ Dict ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ê°•ì œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if payload is None:
        return []

    if isinstance(payload, str):
        text = payload.strip()
        if not text:
            return []
        try:
            parsed = json.loads(text)
        except json.JSONDecodeError:
            return []
        return _ensure_dict_list(parsed)

    if isinstance(payload, dict):
        for key in ("items", "checklists", "tasks", "data", "results"):
            value = payload.get(key)
            if isinstance(value, list):
                return _ensure_dict_list(value)
        return [payload]

    if isinstance(payload, list):
        normalized_items: List[Dict[str, Any]] = []
        for entry in payload:
            if isinstance(entry, dict):
                normalized_items.append(entry)
                continue
            nested_items = _ensure_dict_list(entry)
            if nested_items:
                normalized_items.extend(nested_items)
        return normalized_items

    return []


def _normalize_task_ids(value: Any) -> List[str]:
    """ì‘ì—… ID í•„ë“œë¥¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if value is None:
        return []

    if isinstance(value, str):
        tokens = [token.strip() for token in re.split(r"[,\s]+", value) if token.strip()]
        return tokens

    if isinstance(value, Iterable) and not isinstance(value, (bytes, bytearray)):
        result: List[str] = []
        for item in value:
            if isinstance(item, str):
                text = item.strip()
            else:
                text = str(item).strip()
            if text:
                result.append(text)
        return result

    return []


def _normalize_milestones(
    raw_milestones: Any,
    default_task_ids: List[str]
) -> List[Milestone]:
    """ë§ˆì¼ìŠ¤í†¤ ëª©ë¡ì„ Milestone ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì •ë¦¬í•©ë‹ˆë‹¤."""
    if not isinstance(raw_milestones, Iterable) or isinstance(raw_milestones, (str, bytes, bytearray)):
        return []

    normalized: List[Milestone] = []
    remaining = list(default_task_ids)

    for entry in raw_milestones:
        if not isinstance(entry, dict):
            continue

        name = str(entry.get("name", "")).strip() or "ë§ˆì¼ìŠ¤í†¤"
        deadline = str(entry.get("deadline", "")).strip()
        tasks = _normalize_task_ids(entry.get("tasks"))
        if not tasks:
            if remaining:
                tasks = [remaining.pop(0)]
            else:
                tasks = default_task_ids[:] or []
        else:
            remaining = [task for task in remaining if task not in tasks]

        completion = str(entry.get("completion_criteria", "")).strip()

        normalized.append({
            "name": name,
            "deadline": deadline,
            "tasks": tasks,
            "completion_criteria": completion
        })

    return normalized


def _normalize_dependencies(
    raw_dependencies: Any,
    allowable_tasks: List[str]
) -> Dict[str, List[str]]:
    """ì˜ì¡´ì„± ì •ë³´ë¥¼ Dict[str, List[str]] í˜•íƒœë¡œ ì •ë¦¬í•©ë‹ˆë‹¤."""
    normalized: Dict[str, List[str]] = {}
    if not isinstance(raw_dependencies, dict):
        return normalized

    allowable = set(allowable_tasks)

    for key, value in raw_dependencies.items():
        dep_key = str(key).strip()
        if not dep_key:
            continue
        deps = _normalize_task_ids(value)
        if allowable:
            deps = [dep for dep in deps if dep in allowable]
        normalized[dep_key] = deps

    return normalized


def _normalize_parallel_tasks(
    raw_parallel: Any,
    allowable_tasks: List[str]
) -> List[List[str]]:
    """ë³‘ë ¬ ì‘ì—… ê·¸ë£¹ì„ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    normalized: List[List[str]] = []
    allowable = set(allowable_tasks)

    if raw_parallel is None:
        return normalized

    candidates: Iterable[Any]
    if isinstance(raw_parallel, str):
        candidates = [raw_parallel]
    elif isinstance(raw_parallel, Iterable) and not isinstance(raw_parallel, (bytes, bytearray)):
        candidates = raw_parallel
    else:
        return normalized

    for group in candidates:
        group_items = _normalize_task_ids(group)
        if allowable:
            group_items = [item for item in group_items if item in allowable]
        if group_items:
            normalized.append(group_items)

    return normalized


def save_report_pdf(markdown_text: str, output_dir: Path) -> Path:
    """Markdown ë³´ê³ ì„œë¥¼ HTML+CSSë¡œ ë³€í™˜í•˜ì—¬ PDFë¡œ ì €ì¥í•˜ê³ ,
    ì›ë³¸ markdownë„ .md íŒŒì¼ë¡œ í•¨ê»˜ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        markdown_text: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë³´ê³ ì„œ í…ìŠ¤íŠ¸
        output_dir: PDF ì €ì¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ

    Returns:
        ìƒì„±ëœ PDF íŒŒì¼ì˜ ê²½ë¡œ
    """
    if not markdown_text.strip():
        raise RuntimeError("ìƒì„±ëœ ë³´ê³ ì„œ ë‚´ìš©ì´ ë¹„ì–´ ìˆì–´ PDFë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ì €ì¥ íŒŒì¼ ê²½ë¡œ ì •ì˜ (ë™ì¼ ë² ì´ìŠ¤ ì´ë¦„ìœ¼ë¡œ md & pdf ìƒì„±)
    md_path = output_dir / "regulation_report_reason.md"
    pdf_path = output_dir / "regulation_report_reason.pdf"

    # 1) ì›ë³¸ ë§ˆí¬ë‹¤ìš´ ì €ì¥ (ì¡´ì¬ ì‹œ ë®ì–´ì“°ê¸°)
    md_path.write_text(markdown_text, encoding="utf-8")

    # 2) Markdown â†’ HTML ë³€í™˜
    html_body = markdown(
        markdown_text,
        extensions=["extra", "toc", "tables", "fenced_code"],
    )

    # 3) PDF ìŠ¤íƒ€ì¼ ì •ì˜
    css = CSS(
        string="""
        @page { size: A4; margin: 20mm; }
        body { font-family: 'Apple SD Gothic Neo', 'Nanum Gothic', 'Noto Sans CJK KR', sans-serif; font-size: 11pt; line-height: 1.6; }
        h1, h2, h3 { color: #1a237e; }
        h1 { border-bottom: 3px solid #1a237e; padding-bottom: 10px; }
        h2 { border-bottom: 1px solid #9fa8da; padding-bottom: 5px; margin-top: 20px; }
        ul { margin-left: 0; padding-left: 15px; }
        li { margin-bottom: 6px; }
        table { border-collapse: collapse; width: 100%; margin: 12px 0; }
        th, td { border: 1px solid #bdbdbd; padding: 8px; text-align: left; }
        th { background-color: #e8eaf6; font-weight: bold; }
        code, pre { background: #f5f5f5; padding: 2px 4px; border-radius: 3px; }
        blockquote { border-left: 4px solid #1a237e; padding-left: 10px; color: #555; }
        """
    )

    # 4) HTML ë¬¸ì„œ ì™„ì„± ë° PDF ì €ì¥ (ë™ì¼ ì´ë¦„ ì¡´ì¬ ì‹œ ìë™ ë®ì–´ì“°ê¸°)
    html_doc = f"""
    <html>
      <head>
        <meta charset='utf-8'>
        <title>ê·œì œ ì¤€ìˆ˜ ë¶„ì„ ë³´ê³ ì„œ</title>
      </head>
      <body>{html_body}</body>
    </html>
    """

    HTML(string=html_doc).write_pdf(target=str(pdf_path), stylesheets=[css])

    print(f"âœ“ PDF ë³´ê³ ì„œ ì €ì¥: {pdf_path}")
    print(f"âœ“ Markdown ë³´ê³ ì„œ ì €ì¥: {md_path}")

    return pdf_path


# ============================================
# Tool ì •ì˜ (ê¸°ì¡´ 4ê°œ + ì‹ ê·œ 3ê°œ Agent)
# ============================================

@tool
def analyze_business(business_info: BusinessInfo) -> Dict[str, Any]:
    """ì‚¬ì—… ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê·œì œ ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        business_info: ì‚¬ì—… ì •ë³´ (ì—…ì¢…, ì œí’ˆëª…, ì›ìì¬ ë“±)

    Returns:
        ì¶”ì¶œëœ í‚¤ì›Œë“œ ëª©ë¡
    """
    print("ğŸ” [Analyzer Agent] ì‚¬ì—… ì •ë³´ ë¶„ì„ ì¤‘...")
    print(f"   ì—…ì¢…: {business_info['industry']}")
    print(f"   ì œí’ˆ: {business_info['product_name']}")
    print(f"   ì›ìì¬: {business_info['raw_materials']}")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = f"""
ë‹¤ìŒ ì‚¬ì—… ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê·œì œ ê²€ìƒ‰ì— í•„ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì—…ì¢…: {business_info['industry']}
ì œí’ˆëª…: {business_info['product_name']}
ì›ìì¬: {business_info['raw_materials']}
ì œì¡° ê³µì •: {', '.join(business_info.get('processes', []))}
ì§ì› ìˆ˜: {business_info.get('employee_count', 0)}
íŒë§¤ ë°©ì‹: {', '.join(business_info.get('sales_channels', []))}

ê·œì œì™€ ê´€ë ¨ëœ í‚¤ì›Œë“œë¥¼ 5-7ê°œ ì¶”ì¶œí•˜ë˜, ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
- ì œí’ˆ/ì‚°ì—… ê´€ë ¨ í‚¤ì›Œë“œ
- ì•ˆì „/í™˜ê²½ ê´€ë ¨ í‚¤ì›Œë“œ
- ì¸ì¦/í—ˆê°€ ê´€ë ¨ í‚¤ì›Œë“œ

ì¶œë ¥ í˜•ì‹: í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì„¸ìš”.
ì˜ˆì‹œ: ë°°í„°ë¦¬, í™”í•™ë¬¼ì§ˆ, ì‚°ì—…ì•ˆì „, ì œí’ˆì¸ì¦, ìœ í•´ë¬¼ì§ˆ
"""

    response = llm.invoke(prompt)
    keywords = [k.strip() for k in response.content.split(',')]

    print(f"   âœ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ ({len(keywords)}ê°œ): {keywords}\n")

    return {"keywords": keywords}


@tool
def search_regulations(keywords: List[str]) -> Dict[str, Any]:
    """Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ê·œì œ ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ ëª©ë¡

    Returns:
        ê²€ìƒ‰ëœ ê·œì œ ì •ë³´ ëª©ë¡
    """
    print("ğŸŒ [Search Agent] Tavilyë¡œ ê·œì œ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
    print(f"   ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(keywords[:3])}...")

    # TavilySearch ë„êµ¬ ìƒì„±
    tavily_tool = _build_tavily_tool(max_results=10, search_depth="advanced")

    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    query = f"{' '.join(keywords)} ì œì¡°ì—… ê·œì œ ë²•ë¥  ì•ˆì „ ì¸ì¦ í•œêµ­"

    # Tavily ê²€ìƒ‰ ì‹¤í–‰
    raw = tavily_tool.invoke({"query": query})

    # ê²°ê³¼ ì¶”ì¶œ
    search_results = _extract_results(raw)

    print(f"   âœ“ ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ë¬¸ì„œ ë°œê²¬")
    for idx, result in enumerate(search_results[:3], 1):
        print(f"      {idx}. {result.get('title', 'N/A')[:60]}...")
    if len(search_results) > 3:
        print(f"      ... ì™¸ {len(search_results) - 3}ê°œ\n")
    else:
        print()

    # ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°í™”
    structured_results = []
    for idx, item in enumerate(search_results, 1):
        structured_results.append({
            "source_id": f"SRC-{idx:03d}",
            "title": item.get("title", ""),
            "url": item.get("url", ""),
            "content": _truncate(item.get("content", ""), 300),
            "score": item.get("score", 0.0),
        })

    return {"search_results": structured_results}


@tool
def classify_regulations(
    business_info: BusinessInfo,
    search_results: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì ìš© ê°€ëŠ¥í•œ ê·œì œë¥¼ 3ê°œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

    Args:
        business_info: ì‚¬ì—… ì •ë³´
        search_results: ê²€ìƒ‰ëœ ê·œì œ ì •ë³´

    Returns:
        ë¶„ë¥˜ëœ ê·œì œ ëª©ë¡
    """
    print("ğŸ“‹ [Classifier Agent] ê·œì œ ë¶„ë¥˜ ë° ì ìš©ì„± íŒë‹¨ ì¤‘...")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    search_summary = "\n\n".join([
        f"{r.get('source_id', f'DOC-{i+1}')} | {r.get('title', 'ì œëª© ì—†ìŒ')}\nURL: {r.get('url', 'ë¯¸ê¸°ì¬')}\nìš”ì•½: {r.get('content', '')[:300]}..."
        for i, r in enumerate(search_results[:5])
    ])

    prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ê²€ìƒ‰ ê·¼ê±° ê¸°ë°˜' ê·œì œ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.
ê²€ìƒ‰ ìš”ì•½ì€ [ë¬¸ì„œID]ë¡œ í‘œê¸°ë˜ë©°, ë°˜ë“œì‹œ í•´ë‹¹ IDë¥¼ ì‚¬ìš©í•´ ì¶œì²˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.

[ì‚¬ì—… ì •ë³´]
ì—…ì¢…: {business_info['industry']}
ì œí’ˆ: {business_info['product_name']}
ì›ìì¬: {business_info['raw_materials']}
ê³µì •: {', '.join(business_info.get('processes', []))}
ì§ì› ìˆ˜: {business_info.get('employee_count', 0)}ëª…

[ê²€ìƒ‰ ìš”ì•½]
{search_summary}

[ìƒì„± ì§€ì¹¨]
1) ê²€ìƒ‰ ìš”ì•½ì— ëª…ì‹œëœ ë¬¸ì„œë§Œ ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ê³ , ê° ê·œì œë§ˆë‹¤ 1ê°œ ì´ìƒ ì¶œì²˜ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
2) 5~7ê°œì˜ ê·œì œë¥¼ ì œì•ˆí•˜ë˜, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ì œì™¸í•˜ì„¸ìš”.
3) categoryëŠ” 'ì•ˆì „/í™˜ê²½' | 'ì œí’ˆ ì¸ì¦' | 'ê³µì¥ ìš´ì˜' ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.
4) key_requirementsëŠ” ì‹¤í–‰í˜• ë¬¸ì¥ 2~4ê°œ.
5) reference_urlì€ ì„ íƒí•œ ì¶œì²˜ ì¤‘ ê°€ì¥ ê³µì‹ì ì¸ URLì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
6) ì¶œë ¥ì€ JSON ë°°ì—´ì´ë©°, ê° í•­ëª©ì€ ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¦…ë‹ˆë‹¤.

[
  {{
    "name": "ê·œì œëª…",
    "category": "ì•ˆì „/í™˜ê²½|ì œí’ˆ ì¸ì¦|ê³µì¥ ìš´ì˜",
    "why_applicable": "ì´ ì‚¬ì—…ì— ì ìš©ë˜ëŠ” ì´ìœ ",
    "authority": "ê´€í•  ê¸°ê´€",
    "key_requirements": ["ìš”êµ¬ì‚¬í•­1", "ìš”êµ¬ì‚¬í•­2"],
    "reference_url": "https://...",
    "sources": [
      {{
        "source_id": "SRC-001",
        "excerpt": "ì¶œì²˜ì—ì„œ ì¸ìš©í•œ ê·¼ê±° ë¬¸ì¥"
      }}
    ]
  }}
]

JSON ì´ì™¸ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ì§€ ë§ê³ , sources ë°°ì—´ì€ ìµœëŒ€ 3ê°œê¹Œì§€ í¬í•¨í•˜ì„¸ìš”.
"""

    response = llm.invoke(prompt)

    source_lookup = {item.get("source_id"): item for item in search_results if item.get("source_id")}

    try:
        # JSON íŒŒì‹±
        content = response.content.strip()
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]

        regulations_data = json.loads(content.strip())

        # Regulation í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        regulations = []
        for idx, reg in enumerate(regulations_data, 1):
            source_entries = []
            for src in reg.get("sources", []) or []:
                src_id = src.get("source_id")
                matched = source_lookup.get(src_id, {})
                source_entries.append({
                    "source_id": src_id or f"SRC-{idx:03d}",
                    "title": matched.get("title", ""),
                    "url": matched.get("url", ""),
                    "snippet": src.get("excerpt", matched.get("content", ""))[:300]
                })

            primary_url = reg.get("reference_url") or (source_entries[0]["url"] if source_entries else "")

            if not source_entries and primary_url:
                matched = next(
                    (src for src in source_lookup.values() if src.get("url") == primary_url),
                    {}
                )
                source_entries.append({
                    "source_id": matched.get("source_id", f"SRC-{idx:03d}"),
                    "title": matched.get("title", ""),
                    "url": primary_url,
                    "snippet": matched.get("content", "")[:300]
                })

            regulations.append({
                "id": f"REG-{idx:03d}",
                "name": reg.get("name", "ë¯¸ì§€ì •"),
                "category": reg.get("category", "ì•ˆì „/í™˜ê²½"),
                "why_applicable": reg.get("why_applicable", ""),
                "authority": reg.get("authority", "ë¯¸ì§€ì •"),
                "priority": "MEDIUM",  # ê¸°ë³¸ê°’, Prioritizerì—ì„œ ê²°ì •
                "key_requirements": reg.get("key_requirements", []),
                "reference_url": primary_url,
                "sources": source_entries
            })

        # ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜ ê³„ì‚°
        category_count = {}
        for reg in regulations:
            cat = reg['category']
            category_count[cat] = category_count.get(cat, 0) + 1

        print(f"   âœ“ ê·œì œ ë¶„ë¥˜ ì™„ë£Œ: ì´ {len(regulations)}ê°œ")
        for cat, count in category_count.items():
            print(f"      - {cat}: {count}ê°œ")
        print()

        return {"regulations": regulations}

    except json.JSONDecodeError as e:
        print(f"   âš ï¸  JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"   ì‘ë‹µ ë‚´ìš©: {response.content[:200]}...")
        return {"regulations": []}


@tool
def prioritize_regulations(
    business_info: BusinessInfo,
    regulations: List[Regulation]
) -> Dict[str, Any]:
    """ê·œì œì˜ ìœ„í—˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ìš°ì„ ìˆœìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤ (HIGH/MEDIUM/LOW).

    Args:
        business_info: ì‚¬ì—… ì •ë³´
        regulations: ë¶„ë¥˜ëœ ê·œì œ ëª©ë¡

    Returns:
        ìš°ì„ ìˆœìœ„ê°€ ì§€ì •ëœ ê·œì œ ëª©ë¡
    """
    print("âš¡ [Prioritizer Agent] ìš°ì„ ìˆœìœ„ ê²°ì • ì¤‘...")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    # ê·œì œ ëª©ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    regulations_summary = "\n".join([
        f"{i+1}. {r['name']} ({r['category']})\n   ì´ìœ : {r['why_applicable']}\n   ìš”êµ¬ì‚¬í•­: {', '.join(r['key_requirements'][:2])}"
        for i, r in enumerate(regulations)
    ])

    prompt = f"""
ë‹¤ìŒ ê·œì œë“¤ì˜ ìš°ì„ ìˆœìœ„ë¥¼ HIGH, MEDIUM, LOWë¡œ ê²°ì •í•˜ì„¸ìš”.

[ì‚¬ì—… ì •ë³´]
ì œí’ˆ: {business_info['product_name']}
ì§ì› ìˆ˜: {business_info.get('employee_count', 0)}ëª…

[ê·œì œ ëª©ë¡]
{regulations_summary}

ìš°ì„ ìˆœìœ„ ê¸°ì¤€:
- HIGH: ë²•ì • í•„ìˆ˜ ìš”êµ¬ì‚¬í•­, ìœ„ë°˜ ì‹œ ì‚¬ì—… ì¤‘ë‹¨/ê³ ì•¡ ë²Œê¸ˆ, ì¦‰ì‹œ ì¤€ìˆ˜ í•„ìš”
- MEDIUM: ì¤‘ìš”í•˜ì§€ë§Œ ì¼ì • ê¸°ê°„ ìœ ì˜ˆ ê°€ëŠ¥, ì¤‘ê°„ ìˆ˜ì¤€ ë²Œê¸ˆ
- LOW: ê¶Œì¥ ì‚¬í•­, ì„ íƒì  ì¤€ìˆ˜, ë‚®ì€ ë²Œê¸ˆ

ì¶œë ¥ í˜•ì‹: ê° ê·œì œì˜ ìš°ì„ ìˆœìœ„ë§Œ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì„¸ìš”.
ì˜ˆì‹œ:
HIGH
MEDIUM
HIGH
LOW
"""

    response = llm.invoke(prompt)
    priorities = [p.strip() for p in response.content.strip().split('\n') if p.strip()]

    # ìš°ì„ ìˆœìœ„ í• ë‹¹
    prioritized_regulations = []
    for idx, reg in enumerate(regulations):
        updated_reg = reg.copy()
        if idx < len(priorities):
            priority = priorities[idx]
            if priority in ["HIGH", "MEDIUM", "LOW"]:
                updated_reg['priority'] = priority
            else:
                updated_reg['priority'] = "MEDIUM"
        else:
            updated_reg['priority'] = "MEDIUM"
        prioritized_regulations.append(updated_reg)

    # ìš°ì„ ìˆœìœ„ë³„ ê°œìˆ˜ ê³„ì‚°
    priority_count = {"HIGH": 0, "MEDIUM": 0, "LOW": 0}
    for reg in prioritized_regulations:
        priority_count[reg['priority']] += 1

    print(f"   âœ“ ìš°ì„ ìˆœìœ„ ê²°ì • ì™„ë£Œ:")
    print(f"      - HIGH: {priority_count['HIGH']}ê°œ")
    print(f"      - MEDIUM: {priority_count['MEDIUM']}ê°œ")
    print(f"      - LOW: {priority_count['LOW']}ê°œ\n")

    # ìµœì¢… ê²°ê³¼ ì •ë¦¬
    final_output = {
        "business_info": business_info,
        "total_count": len(prioritized_regulations),
        "regulations": prioritized_regulations,
        "priority_distribution": priority_count
    }

    return {"regulations": prioritized_regulations, "final_output": final_output}


@tool
def generate_checklists(regulations: List[Regulation]) -> Dict[str, Any]:
    """ê° ê·œì œì— ëŒ€í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        regulations: ìš°ì„ ìˆœìœ„ê°€ ê²°ì •ëœ ê·œì œ ëª©ë¡

    Returns:
        ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª© ëª©ë¡
    """
    print("ğŸ“ [Checklist Generator Agent] ê·œì œë³„ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

    all_checklists = []

    # í˜„ì¬ ì‹œìŠ¤í…œ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
    current_date = datetime.now().strftime("%Y-%m-%d")

    for reg in regulations:
        source_summary = "\n".join([
            f"{src.get('source_id','-')} | {src.get('title','ì œëª© ì—†ìŒ')}\nURL: {src.get('url','')}\në°œì·Œ: {src.get('snippet','')}"
            for src in reg.get('sources', [])
        ]) or "ë“±ë¡ëœ ì¶œì²˜ ì—†ìŒ"

        prompt = f"""
ë‹¤ìŒ ê·œì œë¥¼ ì¤€ìˆ˜í•˜ê¸° ìœ„í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.
ê° ì‘ì—…ë§ˆë‹¤ ì‹¤ì œ ì¸í„°ë„· ì¶œì²˜(source_id)ë¥¼ evidence ë°°ì—´ì— í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ê·œì œ ì •ë³´]
ê·œì œëª…: {reg['name']}
ì¹´í…Œê³ ë¦¬: {reg['category']}
ê´€í•  ê¸°ê´€: {reg['authority']}
ìš°ì„ ìˆœìœ„: {reg['priority']}
ì ìš© ì´ìœ : {reg['why_applicable']}
ì£¼ìš” ìš”êµ¬ì‚¬í•­:
{chr(10).join('  - ' + req for req in reg['key_requirements'])}

[ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œì²˜]
{source_summary}

[í˜„ì¬ ë‚ ì§œ]
{current_date}

[ìƒì„± ì§€ì¹¨]
1) ì‘ì—… ìˆ˜: 3~5ê°œ.
2) method[0]ì—ëŠ” "(ë§¤í•‘: ìš”êµ¬ì‚¬í•­ N)" í˜•ì‹ìœ¼ë¡œ ë§¤í•‘ ì •ë³´ë¥¼ ê¸°ì¬í•©ë‹ˆë‹¤.
3) evidenceì—ëŠ” [ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œì²˜]ì—ì„œ ì„ íƒí•œ source_idì™€ í•´ë‹¹ ì¶œì²˜ì˜ í•µì‹¬ ë¬¸ì¥ì„ 1~2ê°œ í¬í•¨í•©ë‹ˆë‹¤.
4) method ë‹¨ê³„ëŠ” 3~5ê°œ, ë§ˆì§€ë§‰ ë‹¨ê³„ì—ëŠ” ì¦ë¹™/ê¸°ë¡ í™•ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
5) deadlineì€ í˜„ì¬ ë‚ ì§œ({current_date})ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ì— ë§ê²Œ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
   - HIGH: í˜„ì¬ì¼ + 1~3ê°œì›”
   - MEDIUM: í˜„ì¬ì¼ + 3~6ê°œì›”
   - LOW: í˜„ì¬ì¼ + 6~12ê°œì›”
6) estimated_timeì€ ì‹¤ì œ ì†Œìš” ì‹œê°„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤ (ì˜ˆ: "2ì£¼", "1ê°œì›”").
7) JSON ë°°ì—´ ì™¸ í…ìŠ¤íŠ¸ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.

[ì¶œë ¥ ìŠ¤í‚¤ë§ˆ]
{{
  "task_name": "êµ¬ì²´ì ì¸ ì‘ì—…ëª…(ëª…ë ¹í˜•)",
  "responsible_dept": "ë‹´ë‹¹ ë¶€ì„œ",
  "deadline": "YYYY-MM-DD",
  "method": [
    "1. (ë§¤í•‘: ìš”êµ¬ì‚¬í•­ N) ...",
    "2. ...",
    "3. ...",
    "4. ...",
    "5. ..."
  ],
  "estimated_time": "ì†Œìš” ì‹œê°„",
  "evidence": [
    {{
      "source_id": "SRC-001",
      "justification": "ì¶œì²˜ì—ì„œ í™•ì¸í•œ í•µì‹¬ ë¬¸ì¥"
    }}
  ]
}}
"""

        response = llm.invoke(prompt)

        try:
            # JSON íŒŒì‹±
            content = response.content.strip()
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]

            raw_payload = json.loads(content.strip())
            checklist_items = _ensure_dict_list(raw_payload)

            if not checklist_items:
                print("      âš ï¸  ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ë‹µì´ ë¹„ì–´ ìˆê±°ë‚˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                continue

            source_lookup = {
                src.get("source_id"): src for src in reg.get("sources", [])
                if src.get("source_id")
            }

            # ChecklistItem í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            for item in checklist_items:
                if not isinstance(item, dict):
                    continue

                evidence_entries = _normalize_evidence_payload(
                    item.get("evidence"),
                    source_lookup
                )

                method_steps = item.get("method") or []
                if isinstance(method_steps, str):
                    method_steps = [method_steps]

                all_checklists.append({
                    "regulation_id": reg['id'],
                    "regulation_name": reg['name'],
                    "task_name": item.get("task_name", ""),
                    "responsible_dept": item.get("responsible_dept", "ë‹´ë‹¹ ë¶€ì„œ"),
                    "deadline": item.get("deadline", "ë¯¸ì •"),
                    "method": method_steps,
                    "estimated_time": item.get("estimated_time", "ë¯¸ì •"),
                    "priority": reg['priority'],
                    "status": "pending",
                    "evidence": evidence_entries
                })

        except json.JSONDecodeError as e:
            print(f"      âš ï¸  JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            continue

    print(f"   âœ“ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: ì´ {len(all_checklists)}ê°œ í•­ëª©\n")

    return {"checklists": all_checklists}


@tool
def plan_execution(
    regulations: List[Regulation],
    checklists: List[ChecklistItem]
) -> Dict[str, Any]:
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íšìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        regulations: ê·œì œ ëª©ë¡
        checklists: ì²´í¬ë¦¬ìŠ¤íŠ¸ ëª©ë¡

    Returns:
        ì‹¤í–‰ ê³„íš ëª©ë¡
    """
    print("ğŸ“… [Planning Agent] ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì¤‘...")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    # ê·œì œë³„ë¡œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê·¸ë£¹í•‘
    checklists_by_regulation = {}
    for item in checklists:
        reg_id = item['regulation_id']
        if reg_id not in checklists_by_regulation:
            checklists_by_regulation[reg_id] = []
        checklists_by_regulation[reg_id].append(item)

    all_execution_plans = []

    for reg in regulations:
        reg_id = reg['id']
        reg_name = reg['name']
        reg_priority = reg['priority']

        # í•´ë‹¹ ê·œì œì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©ë“¤
        reg_checklists = checklists_by_regulation.get(reg_id, [])

        if not reg_checklists:
            continue

        task_ids = [str(i + 1) for i in range(len(reg_checklists))]

        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½
        checklist_summary = "\n".join([
            f"{i+1}. {item['task_name']}\n   ë‹´ë‹¹: {item['responsible_dept']}\n   ë§ˆê°: {item['deadline']}\n   ê¸°ê°„: {item['estimated_time']}"
            for i, item in enumerate(reg_checklists)
        ])

        prompt = f"""
ë‹¤ìŒ ê·œì œì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

[ê·œì œ ì •ë³´]
ê·œì œëª…: {reg_name}
ìš°ì„ ìˆœìœ„: {reg_priority}

[ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©ë“¤]
{checklist_summary}

ë‹¤ìŒ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
1. ì „ì²´ ì˜ˆìƒ ì†Œìš” ê¸°ê°„ (timeline)
2. ì‹œì‘ ì‹œì  (start_date: "ì¦‰ì‹œ", "1ê°œì›” ë‚´", "ê³µì¥ë“±ë¡ í›„" ë“±)
3. ë§ˆì¼ìŠ¤í†¤ (3-5ê°œ, ê° ë§ˆì¼ìŠ¤í†¤ë§ˆë‹¤ name, deadline, completion_criteria í¬í•¨)
4. ì‘ì—… ê°„ ì˜ì¡´ì„± (dependencies: ì–´ë–¤ ì‘ì—…ì´ ë¨¼ì € ì™„ë£Œë˜ì–´ì•¼ í•˜ëŠ”ì§€)
5. ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì—… ê·¸ë£¹ (parallel_tasks)
6. í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤ (critical_path: ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ê²½ë¡œì˜ ì‘ì—… ë²ˆí˜¸ë“¤)

ì¶œë ¥ í˜•ì‹:
{{
    "timeline": "3ê°œì›”",
    "start_date": "ì¦‰ì‹œ",
    "milestones": [
        {{
            "name": "1ê°œì›” ì°¨: ì„œë¥˜ ì¤€ë¹„ ì™„ë£Œ",
            "deadline": "30ì¼ ë‚´",
            "tasks": ["1", "2"],
            "completion_criteria": "í•„ìš” ì„œë¥˜ ëª¨ë‘ ì¤€ë¹„"
        }}
    ],
    "dependencies": {{
        "2": ["1"],
        "3": ["1", "2"]
    }},
    "parallel_tasks": [
        ["1", "2"],
        ["3", "4"]
    ],
    "critical_path": ["1", "2", "5"]
}}

ì°¸ê³ :
- ìš°ì„ ìˆœìœ„ HIGHëŠ” ì¦‰ì‹œ ì‹œì‘
- ìš°ì„ ìˆœìœ„ MEDIUMì€ 1-3ê°œì›” ë‚´
- ìš°ì„ ìˆœìœ„ LOWëŠ” 6ê°œì›” ë‚´
- dependenciesì˜ í‚¤ëŠ” ì‘ì—… ë²ˆí˜¸(ë¬¸ìì—´), ê°’ì€ ì„ í–‰ ì‘ì—… ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
- parallel_tasksëŠ” ë™ì‹œì— ì§„í–‰ ê°€ëŠ¥í•œ ì‘ì—… ê·¸ë£¹ë“¤ì˜ ë¦¬ìŠ¤íŠ¸

ì¶œë ¥ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.
"""

        response = llm.invoke(prompt)

        try:
            # JSON íŒŒì‹±
            content = response.content.strip()
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]

            plan_data = json.loads(content.strip())
            if isinstance(plan_data, list):
                plan_data = plan_data[0] if plan_data else {}
            if not isinstance(plan_data, dict):
                plan_data = {}

            plan_evidence = _merge_evidence([item.get("evidence", []) for item in reg_checklists])

            milestones = _normalize_milestones(
                plan_data.get("milestones"),
                task_ids
            )

            dependencies = _normalize_dependencies(
                plan_data.get("dependencies"),
                task_ids
            )

            parallel_tasks = _normalize_parallel_tasks(
                plan_data.get("parallel_tasks"),
                task_ids
            )

            critical_path = _normalize_task_ids(plan_data.get("critical_path"))
            if task_ids:
                critical_path = [cp for cp in critical_path if cp in task_ids]
                if not critical_path:
                    critical_path = task_ids[:]

            default_start = (
                "ì¦‰ì‹œ" if reg_priority == "HIGH"
                else "1ê°œì›” ë‚´" if reg_priority == "MEDIUM"
                else "3ê°œì›” ë‚´"
            )

            execution_plan: ExecutionPlan = {
                "plan_id": f"PLAN-{len(all_execution_plans) + 1:03d}",
                "regulation_id": reg_id,
                "regulation_name": reg_name,
                "checklist_items": task_ids,
                "timeline": str(plan_data.get("timeline") or "3ê°œì›”"),
                "start_date": str(plan_data.get("start_date") or default_start),
                "milestones": milestones,
                "dependencies": dependencies,
                "parallel_tasks": parallel_tasks,
                "critical_path": critical_path,
                "evidence": plan_evidence
            }

            all_execution_plans.append(execution_plan)

        except json.JSONDecodeError as e:
            print(f"      âš ï¸  JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ì‹¤í–‰ ê³„íš ìƒì„±
            plan_evidence = _merge_evidence([item.get("evidence", []) for item in reg_checklists])

            default_plan: ExecutionPlan = {
                "plan_id": f"PLAN-{len(all_execution_plans) + 1:03d}",
                "regulation_id": reg_id,
                "regulation_name": reg_name,
                "checklist_items": task_ids,
                "timeline": "3ê°œì›”",
                "start_date": "ì¦‰ì‹œ" if reg_priority == "HIGH" else "1ê°œì›” ë‚´",
                "milestones": [],
                "dependencies": {},
                "parallel_tasks": [],
                "critical_path": task_ids,
                "evidence": plan_evidence
            }
            all_execution_plans.append(default_plan)

    print(f"   âœ“ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ì´ {len(all_execution_plans)}ê°œ ê³„íš\n")

    return {"execution_plans": all_execution_plans}


@tool
def assess_risks(
    regulations: List[Regulation],
    business_info: BusinessInfo
) -> Dict[str, Any]:
    """ê·œì œ ë¯¸ì¤€ìˆ˜ ì‹œ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.

    Args:
        regulations: ê·œì œ ëª©ë¡
        business_info: ì‚¬ì—… ì •ë³´

    Returns:
        ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼
    """
    print("âš ï¸  [Risk Assessment Agent] ë¦¬ìŠ¤í¬ í‰ê°€ ì¤‘...")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

    risk_items = []

    for reg in regulations:
        source_summary = "\n".join([
            f"{src.get('source_id','-')} | {src.get('title','ì œëª© ì—†ìŒ')}\nURL: {src.get('url','')}\në°œì·Œ: {src.get('snippet','')}"
            for src in reg.get('sources', [])
        ]) or "ë“±ë¡ëœ ì¶œì²˜ ì—†ìŒ"

        prompt = f"""
ë‹¤ìŒ ê·œì œë¥¼ ì¤€ìˆ˜í•˜ì§€ ì•Šì•˜ì„ ë•Œì˜ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ì„¸ìš”.
ê·¼ê±°ëŠ” [ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œì²˜]ì—ì„œ ì„ íƒí•œ í•­ëª©ë§Œ í™œìš©í•˜ê³  evidence ë°°ì—´ì— í¬í•¨í•˜ì„¸ìš”.

[ê·œì œ ì •ë³´]
ê·œì œëª…: {reg['name']}
ì¹´í…Œê³ ë¦¬: {reg['category']}
ê´€í•  ê¸°ê´€: {reg['authority']}
ìš°ì„ ìˆœìœ„: {reg['priority']}
ì ìš© ì´ìœ : {reg['why_applicable']}

[ì‚¬ì—… ì •ë³´]
ì œí’ˆ: {business_info['product_name']}
ì§ì› ìˆ˜: {business_info.get('employee_count', 0)}ëª…

[ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œì²˜]
{source_summary}

[ì¶œë ¥ ìŠ¤í‚¤ë§ˆ]
{{
  "penalty_amount": "ë²Œê¸ˆì•¡ (ì˜ˆ: ìµœëŒ€ 1ì–µì›, 300ë§Œì› ì´í•˜, ì—†ìœ¼ë©´ \"\")",
  "penalty_type": "ë²Œì¹™ ìœ í˜• (í˜•ì‚¬ì²˜ë²Œ|ê³¼íƒœë£Œ|í–‰ì •ì²˜ë¶„|\"\" )",
  "business_impact": "ì‚¬ì—… ì˜í–¥ (ì˜ˆ: ì˜ì—…ì •ì§€ 6ê°œì›”, ì¸í—ˆê°€ ì·¨ì†Œ, ì—†ìœ¼ë©´ \"\")",
  "risk_score": 0-10 ì‚¬ì´ ìˆ«ì,
  "past_cases": [
    "ê³¼ê±° ì²˜ë²Œ ì‚¬ë¡€ 1 (ì—°ë„, ê¸°ì—…, ì²˜ë²Œ ë‚´ìš©)"
  ],
  "mitigation": "ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆ (1-2ë¬¸ì¥)",
  "evidence": [
    {{
      "source_id": "SRC-001",
      "justification": "ì¶œì²˜ì—ì„œ ì¸ìš©í•œ í•µì‹¬ ë¬¸ì¥"
    }}
  ]
}}

JSON ì´ì™¸ í…ìŠ¤íŠ¸ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.
"""

        response = llm.invoke(prompt)

        try:
            content = response.content.strip()
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]

            risk_data = json.loads(content.strip())

            source_lookup = {
                src.get("source_id"): src for src in reg.get("sources", [])
                if src.get("source_id")
            }

            raw_score = risk_data.get("risk_score", 5.0)
            try:
                risk_score = float(raw_score)
            except (TypeError, ValueError):
                risk_score = 5.0

            evidence_entries = _normalize_evidence_payload(
                risk_data.get("evidence"),
                source_lookup
            )

            risk_item: RiskItem = {
                "regulation_id": reg['id'],
                "regulation_name": reg['name'],
                "penalty_amount": risk_data.get("penalty_amount", "") or "",
                "penalty_type": risk_data.get("penalty_type", "") or "",
                "business_impact": risk_data.get("business_impact", "") or "",
                "risk_score": risk_score,
                "past_cases": risk_data.get("past_cases", []),
                "mitigation": risk_data.get("mitigation", ""),
                "evidence": evidence_entries
            }

            risk_items.append(risk_item)

        except (json.JSONDecodeError, ValueError) as e:
            print(f"      âš ï¸  íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ë¦¬ìŠ¤í¬ ì•„ì´í…œ ì¶”ê°€
            risk_items.append({
                "regulation_id": reg['id'],
                "regulation_name": reg['name'],
                "penalty_amount": "",
                "penalty_type": "",
                "business_impact": "",
                "risk_score": 5.0,
                "past_cases": [],
                "mitigation": "ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥",
                "evidence": []
            })

    # ì „ì²´ ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    if risk_items:
        total_risk_score = sum(item['risk_score'] for item in risk_items) / len(risk_items)
    else:
        total_risk_score = 0.0

    # ê³ ìœ„í—˜ í•­ëª© í•„í„°ë§ (7.0 ì´ìƒ)
    high_risk_items = [item for item in risk_items if item['risk_score'] >= 7.0]

    # ê¶Œì¥ ì‚¬í•­ ìƒì„±
    recommendations = []
    if high_risk_items:
        recommendations.append(f"ê³ ìœ„í—˜ ê·œì œ {len(high_risk_items)}ê°œ - ì¦‰ì‹œ ì¤€ìˆ˜ ì¡°ì¹˜ ì‹œì‘ í•„ìš”")
    if total_risk_score >= 7.0:
        recommendations.append("ë°°ìƒì±…ì„ë³´í—˜ ê°€ì… ê°•ë ¥ ê¶Œì¥")

    # regulationsì—ì„œ HIGH ìš°ì„ ìˆœìœ„ í™•ì¸
    high_priority_count = sum(1 for reg in regulations if reg.get('priority') == 'HIGH')
    if high_priority_count > 0:
        recommendations.append(f"HIGH ìš°ì„ ìˆœìœ„ ê·œì œ {high_priority_count}ê°œ - ì‚¬ì—… ê°œì‹œ ì „ í•„ìˆ˜ ì™„ë£Œ")

    recommendations.append("ì›” 1íšŒ ì¤€ìˆ˜ í˜„í™© ì ê²€ ì²´ê³„ ìˆ˜ë¦½ ê¶Œì¥")

    # ë¦¬ìŠ¤í¬ ë§¤íŠ¸ë¦­ìŠ¤ (ìš°ì„ ìˆœìœ„ x ë¦¬ìŠ¤í¬ ì ìˆ˜)
    risk_matrix = {
        "HIGH": [item for item in risk_items if item['risk_score'] >= 7.0],
        "MEDIUM": [item for item in risk_items if 4.0 <= item['risk_score'] < 7.0],
        "LOW": [item for item in risk_items if item['risk_score'] < 4.0]
    }

    risk_assessment: RiskAssessment = {
        "total_risk_score": round(total_risk_score, 2),
        "high_risk_items": high_risk_items,
        "risk_matrix": risk_matrix,
        "recommendations": recommendations
    }

    print(f"   âœ“ ë¦¬ìŠ¤í¬ í‰ê°€ ì™„ë£Œ: ì „ì²´ ì ìˆ˜ {total_risk_score:.1f}/10")
    print(f"      - ê³ ìœ„í—˜ í•­ëª©: {len(high_risk_items)}ê°œ\n")

    return {"risk_assessment": risk_assessment}


@tool
def generate_final_report(
    business_info: BusinessInfo,
    regulations: List[Regulation],
    checklists: List[ChecklistItem],
    execution_plans: List[ExecutionPlan],
    risk_assessment: RiskAssessment
) -> Dict[str, Any]:
    """ì „ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•© ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œë¡œ ì‘ì„±í•˜ê³  PDFë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        business_info: ì‚¬ì—… ì •ë³´
        regulations: ê·œì œ ëª©ë¡
        checklists: ì²´í¬ë¦¬ìŠ¤íŠ¸
        execution_plans: ì‹¤í–‰ ê³„íš
        risk_assessment: ë¦¬ìŠ¤í¬ í‰ê°€

    Returns:
        ìµœì¢… ë³´ê³ ì„œ (í†µí•© ë§ˆí¬ë‹¤ìš´ + PDF ê²½ë¡œ)
    """
    print("ğŸ“„ [Report Generation Agent] í†µí•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

    # === 1. ê¸°ë³¸ í†µê³„ ê³„ì‚° ===
    priority_count = {"HIGH": 0, "MEDIUM": 0, "LOW": 0}
    category_count = {}
    for reg in regulations:
        priority_count[reg['priority']] += 1
        cat = reg['category']
        category_count[cat] = category_count.get(cat, 0) + 1

    high_risk_items = risk_assessment.get('high_risk_items', [])
    total_risk_score = risk_assessment.get('total_risk_score', 0)
    immediate_actions = [reg for reg in regulations if reg['priority'] == 'HIGH']

    regulation_evidence = _merge_evidence([reg.get('sources', []) for reg in regulations])
    checklist_evidence = _merge_evidence([item.get('evidence', []) for item in checklists])
    execution_plan_evidence = _merge_evidence([plan.get('evidence', []) for plan in execution_plans])
    risk_evidence = _merge_evidence([
        item.get('evidence', []) for bucket in risk_assessment.get('risk_matrix', {}).values()
        for item in bucket
    ] if isinstance(risk_assessment.get('risk_matrix'), dict) else [])
    all_citations = _merge_evidence([
        regulation_evidence,
        checklist_evidence,
        execution_plan_evidence,
        risk_evidence
    ])

    # === 2. í†µí•© ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„± ===
    print("   í†µí•© ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ì‘ì„± ì¤‘...")

    # 2-1. í—¤ë” ë° ì‚¬ì—… ì •ë³´
    full_markdown = f"""# ê·œì œ ì¤€ìˆ˜ ë¶„ì„ í†µí•© ë³´ê³ ì„œ

> ìƒì„±ì¼: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}

---

## 1. ì‚¬ì—… ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì—…ì¢…** | {business_info.get('industry', 'N/A')} |
| **ì œí’ˆëª…** | {business_info.get('product_name', 'N/A')} |
| **ì›ìì¬** | {business_info.get('raw_materials', 'N/A')} |
| **ì œì¡° ê³µì •** | {', '.join(business_info.get('processes', []))} |
| **ì§ì› ìˆ˜** | {business_info.get('employee_count', 0)}ëª… |
| **íŒë§¤ ë°©ì‹** | {', '.join(business_info.get('sales_channels', []))} |

---

## 2. ë¶„ì„ ìš”ì•½

### 2.1 ê·œì œ í˜„í™©
- **ì´ ê·œì œ ê°œìˆ˜**: {len(regulations)}ê°œ
- **ìš°ì„ ìˆœìœ„ ë¶„í¬**:
  - ğŸ”´ HIGH: {priority_count['HIGH']}ê°œ (ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”)
  - ğŸŸ¡ MEDIUM: {priority_count['MEDIUM']}ê°œ (1-3ê°œì›” ë‚´ ì¡°ì¹˜)
  - ğŸŸ¢ LOW: {priority_count['LOW']}ê°œ (6ê°œì›” ë‚´ ì¡°ì¹˜)
- **ì¹´í…Œê³ ë¦¬ ë¶„í¬**:
{chr(10).join(f'  - {cat}: {count}ê°œ' for cat, count in category_count.items())}

### 2.2 ë¦¬ìŠ¤í¬ í‰ê°€
- **ì „ì²´ ë¦¬ìŠ¤í¬ ì ìˆ˜**: {total_risk_score:.1f}/10
- **ê³ ìœ„í—˜ ê·œì œ**: {len(high_risk_items)}ê°œ
- **ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”**: {len(immediate_actions)}ê°œ

---

## 3. ê·œì œ ëª©ë¡ ë° ë¶„ë¥˜
"""

    # 2-2. ì¹´í…Œê³ ë¦¬ë³„ ê·œì œ ëª©ë¡
    categories = list(set(reg['category'] for reg in regulations))
    for i, category in enumerate(categories, 1):
        full_markdown += f"\n### 3.{i} {category}\n\n"

        category_regs = [reg for reg in regulations if reg['category'] == category]
        for j, reg in enumerate(category_regs, 1):
            priority_icon = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}[reg['priority']]
            full_markdown += f"""#### 3.{i}.{j} {priority_icon} {reg['name']}

**ìš°ì„ ìˆœìœ„:** {reg['priority']}
**ê´€í•  ê¸°ê´€:** {reg['authority']}
**ì ìš© ì´ìœ :** {reg['why_applicable']}

**ì£¼ìš” ìš”êµ¬ì‚¬í•­:**

"""
            # ì£¼ìš” ìš”êµ¬ì‚¬í•­ì„ list í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (ê° í•­ëª© ì‚¬ì´ì— ë¹ˆ ì¤„ ì¶”ê°€)
            key_reqs = reg.get('key_requirements', [])
            for idx, req in enumerate(key_reqs):
                full_markdown += f"- {req}"
                # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ ì¤„ë°”ê¿ˆ ì¶”ê°€
                if idx < len(key_reqs) - 1:
                    full_markdown += "\n\n"
                else:
                    full_markdown += "\n"
            full_markdown += "\n"
            if reg.get('penalty'):
                full_markdown += f"**ë²Œì¹™:** {reg['penalty']}\n\n"

            if reg.get('sources'):
                full_markdown += "**ê·¼ê±° ì¶œì²˜:**\n\n"
                for idx, src in enumerate(reg['sources']):
                    link_title = src.get('title') or src.get('url', '').split('/')[2]
                    url = src.get('url', '')
                    # justification ìš°ì„  ì‚¬ìš© (LLM ìš”ì•½), ì—†ìœ¼ë©´ snippet ì‚¬ìš©
                    summary = src.get('justification') or (src.get('snippet') or "").replace('\n', ' ')
                    full_markdown += "  - "
                    if url:
                        full_markdown += f"**[<a href=\"{url}\">{link_title}</a>]**\t{summary}"
                    else:
                        full_markdown += f"**[{link_title}]**\t{summary}"
                    # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ ì¤„ë°”ê¿ˆ ì¶”ê°€
                    if idx < len(reg['sources']) - 1:
                        full_markdown += "\n\n"
                    else:
                        full_markdown += "\n"
                full_markdown += "\n"

    # 2-3. ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
    full_markdown += "\n---\n\n## 4. ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n"

    for reg in regulations:
        reg_checklists = [c for c in checklists if c['regulation_id'] == reg['id']]
        if reg_checklists:
            priority_icon = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}[reg['priority']]
            full_markdown += f"### 4.{regulations.index(reg)+1} {priority_icon} {reg['name']}\n\n"

            for item in reg_checklists:
                full_markdown += f"- [ ] **{item['task_name']}**\n"
                full_markdown += f"  - ë‹´ë‹¹: {item['responsible_dept']}\n"
                full_markdown += f"  - ë§ˆê°: {item['deadline']}\n"
                full_markdown += "\n"
                if item.get('evidence'):
                    full_markdown += "  **ê·¼ê±° ì¶œì²˜:**\n\n"
                    for idx, ev in enumerate(item['evidence']):
                        link_title = ev.get('title') or ev.get('url', '').split('/')[2]
                        url = ev.get('url', '')
                        # justification ìš°ì„  ì‚¬ìš© (LLM ìš”ì•½), ì—†ìœ¼ë©´ snippet ì‚¬ìš©
                        summary = ev.get('justification') or (ev.get('snippet') or "").replace('\n', ' ')
                        full_markdown += "  - "
                        if url:
                            full_markdown += f"**[<a href=\"{url}\">{link_title}</a>]**\t{summary}"
                        else:
                            full_markdown += f"**[{link_title}]**\t{summary}"
                        # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ ì¤„ë°”ê¿ˆ ì¶”ê°€
                        if idx < len(item['evidence']) - 1:
                            full_markdown += "\n\n  "
                        else:
                            full_markdown += "\n"
                    full_markdown += "\n"

    # 2-4. ì‹¤í–‰ ê³„íš ë° íƒ€ì„ë¼ì¸
    full_markdown += "\n---\n\n## 5. ì‹¤í–‰ ê³„íš ë° íƒ€ì„ë¼ì¸\n\n"

    for plan in execution_plans:
        reg_name = plan['regulation_name']
        priority = next((r['priority'] for r in regulations if r['id'] == plan['regulation_id']), 'MEDIUM')
        priority_icon = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}[priority]

        full_markdown += f"### 5.{execution_plans.index(plan)+1} {priority_icon} {reg_name}\n\n"
        full_markdown += f"**íƒ€ì„ë¼ì¸:** {plan['timeline']}  \n"
        full_markdown += f"**ì‹œì‘ ì˜ˆì •:** {plan['start_date']}  \n\n"

        # ë§ˆì¼ìŠ¤í†¤
        if plan.get('milestones'):
            full_markdown += "**ì£¼ìš” ë§ˆì¼ìŠ¤í†¤:**\n\n"
            milestones = plan['milestones']
            for idx, milestone in enumerate(milestones):
                full_markdown += f"- {milestone['name']} (ì™„ë£Œ ëª©í‘œ: {milestone['deadline']})"
                # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ ì¤„ë°”ê¿ˆ ì¶”ê°€
                if idx < len(milestones) - 1:
                    full_markdown += "\n\n"
                else:
                    full_markdown += "\n"
            full_markdown += "\n"

        if plan.get('evidence'):
            full_markdown += "**ê·¼ê±° ì¶œì²˜:**\n\n"
            for idx, ev in enumerate(plan['evidence']):
                link_title = ev.get('title') or ev.get('url', '').split('/')[2]
                url = ev.get('url', '')
                # justification ìš°ì„  ì‚¬ìš© (LLM ìš”ì•½), ì—†ìœ¼ë©´ snippet ì‚¬ìš©
                summary = ev.get('justification') or (ev.get('snippet') or "").replace('\n', ' ')
                full_markdown += "  - "
                if url:
                    full_markdown += f"**[<a href=\"{url}\">{link_title}</a>]**\t{summary}"
                else:
                    full_markdown += f"**[{link_title}]**\t{summary}"
                # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ ì¤„ë°”ê¿ˆ ì¶”ê°€
                if idx < len(plan['evidence']) - 1:
                    full_markdown += "\n\n"
                else:
                    full_markdown += "\n"
            full_markdown += "\n"

    # 2-5. ë¦¬ìŠ¤í¬ í‰ê°€
    full_markdown += "\n---\n\n## 6. ë¦¬ìŠ¤í¬ í‰ê°€\n\n"
    full_markdown += f"### 6.1 ì „ì²´ ë¦¬ìŠ¤í¬ í‰ê°€\n\n"
    full_markdown += f"**ì „ì²´ ë¦¬ìŠ¤í¬ ì ìˆ˜:** {total_risk_score:.1f}/10\n\n"

    risk_level = "ë§¤ìš° ë†’ìŒ" if total_risk_score >= 8 else "ë†’ìŒ" if total_risk_score >= 6 else "ì¤‘ê°„"
    full_markdown += f"**ë¦¬ìŠ¤í¬ ìˆ˜ì¤€:** {risk_level}\n\n"

    if high_risk_items:
        full_markdown += "### 6.2 ê³ ìœ„í—˜ ê·œì œ (ìƒìœ„ 5ê°œ)\n\n"
        for item in high_risk_items[:5]:
            full_markdown += f"#### {item['regulation_name']}\n\n"
            full_markdown += f"**ë¦¬ìŠ¤í¬ ì ìˆ˜:** {item['risk_score']}/10\n\n"
            full_markdown += f"**ì²˜ë²Œ ìœ í˜•:** {item['penalty_type']}\n\n"
            full_markdown += f"**ì‚¬ì—… ì˜í–¥:** {item['business_impact']}\n\n"

            if item.get('mitigation_priority'):
                full_markdown += f"**ì™„í™” ìš°ì„ ìˆœìœ„:** {item['mitigation_priority']}\n\n"

            if item.get('evidence'):
                full_markdown += "**ê·¼ê±° ì¶œì²˜:**\n\n"
                for idx, ev in enumerate(item['evidence']):
                    link_title = ev.get('title') or ev.get('url', '').split('/')[2]
                    url = ev.get('url', '')
                    # justification ìš°ì„  ì‚¬ìš© (LLM ìš”ì•½), ì—†ìœ¼ë©´ snippet ì‚¬ìš©
                    summary = ev.get('justification') or (ev.get('snippet') or "").replace('\n', ' ')
                    full_markdown += "  - "
                    if url:
                        full_markdown += f"**[<a href=\"{url}\">{link_title}</a>]**\t{summary}"
                    else:
                        full_markdown += f"**[{link_title}]**\t{summary}"
                    # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ ì¤„ë°”ê¿ˆ ì¶”ê°€
                    if idx < len(item['evidence']) - 1:
                        full_markdown += "\n\n"
                    else:
                        full_markdown += "\n"
                full_markdown += "\n"

    # 2-6. ê²½ì˜ì§„ ìš”ì•½ (LLMìœ¼ë¡œ ìƒì„±)
    print("   ê²½ì˜ì§„ ìš”ì•½ ìƒì„± ì¤‘...")

    exec_summary_prompt = f"""
ë‹¤ìŒ ê·œì œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²½ì˜ì§„ì„ ìœ„í•œ í•µì‹¬ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.

[ë¶„ì„ ê²°ê³¼]
- ì´ ê·œì œ: {len(regulations)}ê°œ
- HIGH: {priority_count['HIGH']}ê°œ, MEDIUM: {priority_count['MEDIUM']}ê°œ, LOW: {priority_count['LOW']}ê°œ
- ë¦¬ìŠ¤í¬ ì ìˆ˜: {total_risk_score:.1f}/10
- ê³ ìœ„í—˜ ê·œì œ: {len(high_risk_items)}ê°œ

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ë§ˆí¬ë‹¤ìš´):

### í•µì‹¬ ì¸ì‚¬ì´íŠ¸
- ì¸ì‚¬ì´íŠ¸ 1 (êµ¬ì²´ì  ìˆ«ì í¬í•¨)
- ì¸ì‚¬ì´íŠ¸ 2
- ì¸ì‚¬ì´íŠ¸ 3

### ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸
- [ ] ê²°ì • ì‚¬í•­ 1
- [ ] ê²°ì • ì‚¬í•­ 2
- [ ] ê²°ì • ì‚¬í•­ 3

### ê¶Œì¥ ì¡°ì¹˜ (ìš°ì„ ìˆœìœ„ ìˆœ)
1. **ì¦‰ì‹œ:** [ì¡°ì¹˜ ë‚´ìš©]
2. **1ê°œì›” ë‚´:** [ì¡°ì¹˜ ë‚´ìš©]
3. **3ê°œì›” ë‚´:** [ì¡°ì¹˜ ë‚´ìš©]

ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
"""

    exec_response = llm.invoke(exec_summary_prompt)
    executive_summary = exec_response.content.strip()

    full_markdown += f"\n---\n\n## 7. ê²½ì˜ì§„ ìš”ì•½\n\n{executive_summary}\n"

    # 2-7. Next Steps
    full_markdown += "\n---\n\n## 8. ë‹¤ìŒ ë‹¨ê³„\n\n"

    next_steps = [
        f"**1ë‹¨ê³„ (ì¦‰ì‹œ):** HIGH ìš°ì„ ìˆœìœ„ {priority_count['HIGH']}ê°œ ê·œì œ ì°©ìˆ˜",
        "**2ë‹¨ê³„ (1ì£¼ì¼ ë‚´):** ë‹´ë‹¹ ë¶€ì„œ ë° ì±…ì„ì ì§€ì •",
        "**3ë‹¨ê³„ (2ì£¼ì¼ ë‚´):** ìƒì„¸ ì‹¤í–‰ ì¼ì • í™•ì • ë° ì˜ˆì‚° ìŠ¹ì¸",
        "**4ë‹¨ê³„ (1ê°œì›”):** ì›” ë‹¨ìœ„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
        "**5ë‹¨ê³„ (ë¶„ê¸°ë³„):** ì „ë¬¸ê°€ ê²€í†  ë° ë³´ì™„"
    ]

    for step in next_steps:
        full_markdown += f"- {step}\n"

    if all_citations:
        full_markdown += "\n---\n\n## 9. ê·¼ê±° ì¶œì²˜ ëª¨ìŒ\n\n"
        for idx, citation in enumerate(all_citations, 1):
            link_title = citation.get('title') or citation.get('url', '').split('/')[2]
            url = citation.get('url', '')
            # justification ìš°ì„  ì‚¬ìš© (LLM ìš”ì•½), ì—†ìœ¼ë©´ snippet ì‚¬ìš©
            summary = citation.get('justification') or (citation.get('snippet') or "").replace('\n', ' ')
            full_markdown += "  - "
            if url:
                full_markdown += f"**[<a href=\"{url}\">{link_title}</a>]**\t{summary}"
            else:
                full_markdown += f"**[{link_title}]**\t{summary}"
            # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ ì¤„ë°”ê¿ˆ ì¶”ê°€
            if idx < len(all_citations):
                full_markdown += "\n\n"
            else:
                full_markdown += "\n"

    # 2-8. ë©´ì±… ì¡°í•­
    full_markdown += "\n---\n\n## ë©´ì±… ì¡°í•­\n\n"
    full_markdown += "> ë³¸ ë³´ê³ ì„œëŠ” AI ê¸°ë°˜ ë¶„ì„ ë„êµ¬ë¡œ ìƒì„±ëœ ì°¸ê³  ìë£Œì…ë‹ˆë‹¤. "
    full_markdown += "ì‹¤ì œ ê·œì œ ì¤€ìˆ˜ ì—¬ë¶€ëŠ” ë°˜ë“œì‹œ ì „ë¬¸ê°€ì˜ ê²€í† ë¥¼ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤. "
    full_markdown += "ë³¸ ë³´ê³ ì„œ ë‚´ìš©ìœ¼ë¡œ ì¸í•œ ë²•ì  ì±…ì„ì€ ì‚¬ìš©ìì—ê²Œ ìˆìŠµë‹ˆë‹¤.\n"

    # === 3. ì¸ì‚¬ì´íŠ¸ ë° ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ (êµ¬ì¡°í™”ëœ ë°ì´í„°) ===
    print("   í•µì‹¬ ë°ì´í„° ì¶”ì¶œ ì¤‘...")

    key_insights = [
        f"ì´ {len(regulations)}ê°œ ê·œì œ ì ìš© ëŒ€ìƒ - ì²´ê³„ì  ì¤€ìˆ˜ ê´€ë¦¬ í•„ìš”",
        f"HIGH ìš°ì„ ìˆœìœ„ {priority_count['HIGH']}ê°œ ê·œì œëŠ” ì‚¬ì—… ê°œì‹œ ì „ í•„ìˆ˜ ì™„ë£Œ",
        f"ì „ì²´ ë¦¬ìŠ¤í¬ ì ìˆ˜ {total_risk_score:.1f}/10 - {'ì¦‰ê° ëŒ€ì‘ í•„ìš”' if total_risk_score >= 7 else 'ì „ë¬¸ê°€ ì»¨ì„¤íŒ… ê¶Œì¥'}"
    ]

    action_items = []
    for reg in immediate_actions[:3]:
        action_items.append({
            "name": f"{reg['name']} ì¤€ìˆ˜ ì¡°ì¹˜ ì‹œì‘",
            "deadline": "ì¦‰ì‹œ",
            "priority": "HIGH"
        })

    risk_highlights = []
    for item in high_risk_items[:3]:
        penalty = item.get('penalty_type') or "ì œì¬ ì •ë³´ ì—†ìŒ"
        impact = item.get('business_impact') or "ì˜í–¥ ì •ë³´ ë¯¸ê¸°ì¬"
        risk_highlights.append(
            f"{item['regulation_name']} ë¯¸ì¤€ìˆ˜ ì‹œ {penalty} - {impact}"
        )

    # === 4. PDF ì €ì¥ ===
    print("   PDF íŒŒì¼ ìƒì„± ì¤‘...")

    try:
        pdf_path = save_report_pdf(full_markdown, Path("report"))
        report_pdf_path = str(pdf_path)
        print(f"   âœ“ PDF ì €ì¥ ì™„ë£Œ: {report_pdf_path}")
    except Exception as e:
        print(f"   âš  PDF ìƒì„± ì‹¤íŒ¨: {e}")
        report_pdf_path = "PDF ìƒì„± ì‹¤íŒ¨"

    # === 5. ìµœì¢… ë³´ê³ ì„œ ë°˜í™˜ ===
    final_report: FinalReport = {
        "executive_summary": executive_summary,
        "detailed_report": "",  # í†µí•© ë³´ê³ ì„œë¡œ ëŒ€ì²´
        "legal_report": "",     # í†µí•© ë³´ê³ ì„œë¡œ ëŒ€ì²´
        "key_insights": key_insights,
        "action_items": action_items,
        "risk_highlights": risk_highlights,
        "next_steps": next_steps,
        "full_markdown": full_markdown,
        "report_pdf_path": report_pdf_path,
        "citations": all_citations
    }

    print(f"   âœ“ í†µí•© ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ\n")

    return {"final_report": final_report}


# ============================================
# LangGraph ë…¸ë“œ - ê° Toolì„ í˜¸ì¶œí•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸
# ============================================

def analyzer_node(state: AgentState) -> Dict[str, Any]:
    """ë¶„ì„ ë…¸ë“œ: ì‚¬ì—… ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    result = analyze_business.invoke({"business_info": state["business_info"]})
    return {"keywords": result["keywords"]}


def search_node(state: AgentState) -> Dict[str, Any]:
    """ê²€ìƒ‰ ë…¸ë“œ: í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê·œì œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    result = search_regulations.invoke({"keywords": state["keywords"]})
    return {"search_results": result["search_results"]}


def classifier_node(state: AgentState) -> Dict[str, Any]:
    """ë¶„ë¥˜ ë…¸ë“œ: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ê·œì œë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    result = classify_regulations.invoke({
        "business_info": state["business_info"],
        "search_results": state["search_results"]
    })
    return {"regulations": result["regulations"]}


def prioritizer_node(state: AgentState) -> Dict[str, Any]:
    """ìš°ì„ ìˆœìœ„ ë…¸ë“œ: ê·œì œì˜ ìš°ì„ ìˆœìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    result = prioritize_regulations.invoke({
        "business_info": state["business_info"],
        "regulations": state["regulations"]
    })
    return {
        "regulations": result["regulations"],
        "final_output": result["final_output"]
    }


def checklist_generator_node(state: AgentState) -> Dict[str, Any]:
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ë…¸ë“œ: ê·œì œë³„ ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    result = generate_checklists.invoke({"regulations": state["regulations"]})
    return {"checklists": result["checklists"]}


def planning_agent_node(state: AgentState) -> Dict[str, Any]:
    """ì‹¤í–‰ ê³„íš ë…¸ë“œ: ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤í–‰ ê³„íšìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    result = plan_execution.invoke({
        "regulations": state["regulations"],
        "checklists": state["checklists"]
    })
    return {"execution_plans": result["execution_plans"]}


def risk_assessor_node(state: AgentState) -> Dict[str, Any]:
    """ë¦¬ìŠ¤í¬ í‰ê°€ ë…¸ë“œ: ë¯¸ì¤€ìˆ˜ ì‹œ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
    result = assess_risks.invoke({
        "regulations": state["regulations"],
        "business_info": state["business_info"]
    })
    return {"risk_assessment": result["risk_assessment"]}


def report_generator_node(state: AgentState) -> Dict[str, Any]:
    """ë³´ê³ ì„œ ìƒì„± ë…¸ë“œ: ì „ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•© ë³´ê³ ì„œë¡œ ì‘ì„±í•©ë‹ˆë‹¤."""
    result = generate_final_report.invoke({
        "business_info": state["business_info"],
        "regulations": state["regulations"],
        "checklists": state["checklists"],
        "execution_plans": state["execution_plans"],
        "risk_assessment": state["risk_assessment"]
    })
    return {"final_report": result["final_report"]}


# ============================================
# ê·¸ë˜í”„ ë¹Œë“œ ë° ì‹¤í–‰
# ============================================

def build_workflow() -> StateGraph:
    """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

    ì‹¤í–‰ ìˆœì„œ (ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”):
    1. analyzer: ì‚¬ì—… ì •ë³´ ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
    2. searcher: Tavilyë¡œ ê·œì œ ê²€ìƒ‰
    3. classifier: ê·œì œ ë¶„ë¥˜
    4. prioritizer: ìš°ì„ ìˆœìœ„ ê²°ì •
    5-6. [ë³‘ë ¬ ì‹¤í–‰]
         - checklist_generator: ê·œì œë³„ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
         - risk_assessor: ë¦¬ìŠ¤í¬ í‰ê°€
    7. planning_agent: ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ (checklist_generator ì™„ë£Œ í›„)
    8. report_generator: ìµœì¢… ë³´ê³ ì„œ ìƒì„± (planning_agent + risk_assessor ì™„ë£Œ í›„)

    ë³‘ë ¬í™” ì´ì : Risk Assessment Agentê°€ Checklist Generator/Planning Agentì™€
                ë™ì‹œ ì‹¤í–‰ë˜ì–´ ì „ì²´ ì†Œìš” ì‹œê°„ ì•½ 30ì´ˆ~1ë¶„ ë‹¨ì¶•
    """
    graph = StateGraph(AgentState)

    # ê¸°ì¡´ Agent ë…¸ë“œ
    graph.add_node("analyzer", analyzer_node)
    graph.add_node("searcher", search_node)
    graph.add_node("classifier", classifier_node)
    graph.add_node("prioritizer", prioritizer_node)
    graph.add_node("checklist_generator", checklist_generator_node)
    graph.add_node("risk_assessor", risk_assessor_node)

    # ì‹ ê·œ Agent ë…¸ë“œ
    graph.add_node("planning_agent", planning_agent_node)
    graph.add_node("report_generator", report_generator_node)

    # ì—£ì§€ ì¶”ê°€: ìˆœì°¨ ì‹¤í–‰ (Prioritizerê¹Œì§€)
    graph.add_edge(START, "analyzer")
    graph.add_edge("analyzer", "searcher")
    graph.add_edge("searcher", "classifier")
    graph.add_edge("classifier", "prioritizer")

    # ë³‘ë ¬ ì‹¤í–‰: Prioritizer ì´í›„ Checklist Generatorì™€ Risk Assessor ë™ì‹œ ì‹œì‘
    graph.add_edge("prioritizer", "checklist_generator")
    graph.add_edge("prioritizer", "risk_assessor")

    # Checklist Generator â†’ Planning Agent (ìˆœì°¨)
    graph.add_edge("checklist_generator", "planning_agent")

    # Report GeneratorëŠ” Planning Agentì™€ Risk Assessor ëª¨ë‘ ì™„ë£Œ í›„ ì‹¤í–‰
    graph.add_edge("planning_agent", "report_generator")
    graph.add_edge("risk_assessor", "report_generator")

    graph.add_edge("report_generator", END)

    return graph


def run_regulation_agent(business_info: BusinessInfo) -> AgentState:
    """ê·œì œ AI Agentë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Args:
        business_info: ì‚¬ì—… ì •ë³´

    Returns:
        ìµœì¢… ìƒíƒœ ê°ì²´ (ë¶„ì„ ê²°ê³¼ í¬í•¨)
    """
    # ì›Œí¬í”Œë¡œìš° ë¹Œë“œ ë° ì»´íŒŒì¼
    workflow = build_workflow()
    app = workflow.compile(checkpointer=MemorySaver())

    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state: AgentState = {
        "business_info": business_info,
        "keywords": [],
        "search_results": [],
        "regulations": [],
        "final_output": {},
        # Agent ê²°ê³¼ í•„ë“œ ì´ˆê¸°í™”
        "checklists": [],
        "execution_plans": [],
        "risk_assessment": {
            "total_risk_score": 0.0,
            "high_risk_items": [],
            "risk_matrix": {},
            "recommendations": []
        },
        "final_report": {
            "executive_summary": "",
            "detailed_report": "",
            "legal_report": "",
            "key_insights": [],
            "action_items": [],
            "risk_highlights": [],
            "next_steps": [],
            "full_markdown": "",
            "report_pdf_path": "",
            "citations": []
        }
    }

    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    config = {"configurable": {"thread_id": "regulation_agent_v3"}}
    return app.invoke(initial_state, config=config)


# ============================================
# ì¶œë ¥ í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================

def print_checklists(checklists: List[ChecklistItem]):
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("ğŸ“‹ ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸")
    print("=" * 60)
    print(f"ì´ {len(checklists)}ê°œ í•­ëª©\n")

    # ê·œì œë³„ë¡œ ê·¸ë£¹í•‘
    checklists_by_regulation = {}
    for item in checklists:
        reg_id = item['regulation_id']
        if reg_id not in checklists_by_regulation:
            checklists_by_regulation[reg_id] = []
        checklists_by_regulation[reg_id].append(item)

    # ì¶œë ¥
    for reg_id, items in checklists_by_regulation.items():
        regulation_name = items[0]['regulation_name']
        priority = items[0]['priority']

        priority_emoji = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}
        emoji = priority_emoji.get(priority, "âšª")

        print(f"{emoji} [{priority}] {regulation_name}")
        print("-" * 60)

        for idx, item in enumerate(items, 1):
            print(f"\n   {idx}. {item['task_name']}")
            print(f"      ë‹´ë‹¹: {item['responsible_dept']}")
            print(f"      ë§ˆê°: {item['deadline']}")
            print(f"      ê¸°ê°„: {item['estimated_time']}")
            if item['method']:
                print(f"      ì‹¤í–‰ ë°©ë²•:")
                for method in item['method'][:3]:  # ìµœëŒ€ 3ë‹¨ê³„ë§Œ í‘œì‹œ
                    print(f"         {method}")
            if item.get('evidence'):
                print("      ê·¼ê±°:")
                for ev in item['evidence'][:2]:
                    title = ev.get("title") or ev.get("url", "")
                    url = ev.get("url", "")
                    print(f"         - {title} ({url})")

        print()


def print_execution_plans(execution_plans: List[ExecutionPlan]):
    """ì‹¤í–‰ ê³„íšì„ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("ğŸ“… ì‹¤í–‰ ê³„íš")
    print("=" * 60)
    print(f"ì´ {len(execution_plans)}ê°œ ê³„íš\n")

    for plan in execution_plans:
        print(f"ğŸ¯ {plan['regulation_name']}")
        print(f"   ê³„íš ID: {plan['plan_id']}")
        print(f"   ì˜ˆìƒ ê¸°ê°„: {plan['timeline']}")
        print(f"   ì‹œì‘ ì‹œì : {plan['start_date']}")
        print()

        # ë§ˆì¼ìŠ¤í†¤
        milestones = plan.get('milestones', [])
        if milestones:
            print(f"   ğŸ“Œ ë§ˆì¼ìŠ¤í†¤:")
            for milestone in milestones:
                print(f"      â€¢ {milestone.get('name', '')} ({milestone.get('deadline', '')})")
                print(f"        ì™„ë£Œ ê¸°ì¤€: {milestone.get('completion_criteria', '')}")
        print()

        # ì˜ì¡´ì„±
        dependencies = plan.get('dependencies', {})
        if dependencies:
            print(f"   ğŸ”— ì‘ì—… ì˜ì¡´ì„±:")
            for task, prereqs in list(dependencies.items())[:3]:
                print(f"      ì‘ì—… {task}ëŠ” ì‘ì—… {', '.join(prereqs)} ì™„ë£Œ í›„")
        print()

        # ë³‘ë ¬ ì‘ì—…
        parallel_tasks = plan.get('parallel_tasks', [])
        if parallel_tasks:
            print(f"   âš¡ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥:")
            for group in parallel_tasks[:2]:
                print(f"      ì‘ì—… {', '.join(group)}ëŠ” ë™ì‹œ ì§„í–‰ ê°€ëŠ¥")
        print()

        evidence = plan.get('evidence', [])
        if evidence:
            print("   ğŸ“ ê·¼ê±°:")
            for ev in evidence[:3]:
                title = ev.get("title") or ev.get("url", "")
                url = ev.get("url", "")
                print(f"      - {title} ({url})")
            print()

        # í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤
        critical_path = plan.get('critical_path', [])
        if critical_path:
            print(f"   ğŸ›¤ï¸  í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤: {' â†’ '.join(critical_path)}")
        print("-" * 60)
        print()


def print_final_report(final_report: FinalReport):
    """ìµœì¢… ë³´ê³ ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("ğŸ“„ ìµœì¢… ë³´ê³ ì„œ")
    print("=" * 60)
    print()

    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
    key_insights = final_report.get('key_insights', [])
    if key_insights:
        print("ğŸ“Œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:")
        for idx, insight in enumerate(key_insights, 1):
            print(f"   {idx}. {insight}")
        print()

    # ì¦‰ì‹œ ì¡°ì¹˜ í•­ëª©
    action_items = final_report.get('action_items', [])
    if action_items:
        print("ğŸ¯ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”:")
        for item in action_items:
            print(f"   â€¢ {item.get('name', '')} (ë§ˆê°: {item.get('deadline', '')})")
        print()

    # ì£¼ìš” ë¦¬ìŠ¤í¬
    risk_highlights = final_report.get('risk_highlights', [])
    if risk_highlights:
        print("âš ï¸  ì£¼ìš” ë¦¬ìŠ¤í¬:")
        for risk in risk_highlights:
            print(f"   â€¢ {risk}")
        print()

    # ë‹¤ìŒ ë‹¨ê³„
    next_steps = final_report.get('next_steps', [])
    if next_steps:
        print("ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­:")
        for step in next_steps:
            print(f"   {step}")
        print()

    citations = final_report.get('citations', [])
    if citations:
        print("ğŸ”— ì£¼ìš” ì¶œì²˜:")
        for ev in citations[:5]:
            title = ev.get("title") or ev.get("url", "")
            url = ev.get("url", "")
            print(f"   - {title} ({url})")
        if len(citations) > 5:
            print("   ...")
        print()

    # ê²½ì˜ì§„ìš© ìš”ì•½ (ì¼ë¶€ë§Œ í‘œì‹œ)
    exec_summary = final_report.get('executive_summary', '')
    if exec_summary:
        print("ğŸ“Š ê²½ì˜ì§„ ìš”ì•½ ë³´ê³ ì„œ (ë¯¸ë¦¬ë³´ê¸°):")
        lines = exec_summary.split('\n')[:10]
        print('\n'.join(f"   {line}" for line in lines))
        if len(exec_summary.split('\n')) > 10:
            print("   ... (ì „ì²´ ë‚´ìš©ì€ JSON íŒŒì¼ ì°¸ì¡°)")
        print()


def print_risk_assessment(risk_assessment: RiskAssessment):
    """ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("âš ï¸  ë¦¬ìŠ¤í¬ í‰ê°€")
    print("=" * 60)
    print()

    total_score = risk_assessment.get('total_risk_score', 0)
    risk_level = "ë‚®ìŒ" if total_score < 4.0 else "ë³´í†µ" if total_score < 7.0 else "ë†’ìŒ"
    risk_emoji = "ğŸŸ¢" if total_score < 4.0 else "ğŸŸ¡" if total_score < 7.0 else "ğŸ”´"

    print(f"{risk_emoji} ì „ì²´ ë¦¬ìŠ¤í¬ ì ìˆ˜: {total_score:.1f}/10 ({risk_level})\n")

    # ê³ ìœ„í—˜ í•­ëª©
    high_risk_items = risk_assessment.get('high_risk_items', [])
    if high_risk_items:
        print(f"ğŸš¨ ê³ ìœ„í—˜ ê·œì œ ({len(high_risk_items)}ê°œ):")
        print("-" * 60)
        for item in high_risk_items:
            print(f"\n   [{item['risk_score']:.1f}] {item['regulation_name']}")
            print(f"      ë²Œì¹™: {item['penalty_type']} - {item['penalty_amount']}")
            print(f"      ì˜í–¥: {item['business_impact']}")
            if item['past_cases']:
                print(f"      ê³¼ê±° ì‚¬ë¡€:")
                for case in item['past_cases'][:2]:
                    print(f"         - {case}")
            if item['mitigation']:
                print(f"      ì™„í™” ë°©ì•ˆ: {item['mitigation']}")
            if item.get('evidence'):
                print("      ê·¼ê±°:")
                for ev in item['evidence'][:2]:
                    title = ev.get("title") or ev.get("url", "")
                    url = ev.get("url", "")
                    print(f"         - {title} ({url})")
        print()

    # ê¶Œì¥ ì‚¬í•­
    recommendations = risk_assessment.get('recommendations', [])
    if recommendations:
        print("ğŸ’¡ ê¶Œì¥ ì‚¬í•­:")
        for rec in recommendations:
            print(f"   â€¢ {rec}")
        print()


# ============================================
# Main ì‹¤í–‰ í•¨ìˆ˜
# ============================================

def main():
    """ìƒ˜í”Œ ë°ì´í„°ë¡œ Workflow ì‹¤í–‰"""
    start_time = time.time()

    print("=" * 60)
    print("ğŸ¤– ê·œì œ AI Agent ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    print()

    # ìƒ˜í”Œ ì‚¬ì—… ì •ë³´ (ë°°í„°ë¦¬ ì œì¡°ì—…)
    sample_business_info: BusinessInfo = {
        "industry": "ë°°í„°ë¦¬ ì œì¡°",
        "product_name": "ë¦¬íŠ¬ì´ì˜¨ ë°°í„°ë¦¬",
        "raw_materials": "ë¦¬íŠ¬, ì½”ë°œíŠ¸, ë‹ˆì¼ˆ",
        "processes": ["í™”í•™ ì²˜ë¦¬", "ê³ ì˜¨ ê°€ê³µ", "ì¡°ë¦½"],
        "employee_count": 45,
        "sales_channels": ["B2B", "ìˆ˜ì¶œ"],
        "export_countries": ["ë¯¸êµ­", "ìœ ëŸ½"]
    }
    
    # ë‹¤ë¥¸ ìƒ˜í”Œ ì‚¬ì—… ì •ë³´ (ì „ìì œí’ˆ ì œì¡°)
    sample_business_info2: BusinessInfo = {
    "industry": "ì „ìì œí’ˆ ì œì¡°",
    "product_name": "ìŠ¤ë§ˆíŠ¸ LED ì „êµ¬ (Wi-Fi)",
    "raw_materials": "ABS ìˆ˜ì§€, PCB, êµ¬ë¦¬, LED ì¹©, ì£¼ì„-ì€ ë‚©ë•œ í•©ê¸ˆ",
    "processes": ["ì‚¬ì¶œ ì„±í˜•", "SMT(í‘œë©´ì‹¤ì¥)", "ë‚©ë•œ ë¦¬í”Œë¡œìš°", "íŒì›¨ì–´ í”Œë˜ì‹±", "ìµœì¢… ì¡°ë¦½", "ê¸°ëŠ¥/ì•ˆì „ ì‹œí—˜"],
    "employee_count": 80,
    "sales_channels": ["B2C", "ì˜¨ë¼ì¸", "ì˜¤í”„ë¼ì¸ ë¦¬í…Œì¼", "ìˆ˜ì¶œ"],
    "export_countries": ["ë¯¸êµ­", "ìœ ëŸ½ì—°í•©(EU)", "ì¼ë³¸"]
}

    select = sys.argv[1] if len(sys.argv) > 1 else "1"
    
    print("ğŸ“ ì…ë ¥ëœ ì‚¬ì—… ì •ë³´:")
    print(json.dumps(sample_business_info if select == "1" else sample_business_info2, indent=2, ensure_ascii=False))
    print()
    print("-" * 60)
    print()

    # Workflow ì‹¤í–‰
    try:
        result = run_regulation_agent(sample_business_info if select == "1" else sample_business_info2)
    except Exception as exc:
        print(f"[ERROR] ë¶„ì„ íŒŒì´í”„ë¼ì¸ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {exc}")
        raise

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("=" * 60)
    print("âœ… ë¶„ì„ ì™„ë£Œ - ìµœì¢… ê²°ê³¼")
    print("=" * 60)
    print()

    final_output = result.get('final_output', {})

    print(f"ğŸ“Š ìš”ì•½")
    print(f"   ì´ ê·œì œ ê°œìˆ˜: {final_output.get('total_count', 0)}ê°œ")
    print(f"   ìš°ì„ ìˆœìœ„ ë¶„í¬:")
    priority_dist = final_output.get('priority_distribution', {})
    print(f"      - HIGH: {priority_dist.get('HIGH', 0)}ê°œ")
    print(f"      - MEDIUM: {priority_dist.get('MEDIUM', 0)}ê°œ")
    print(f"      - LOW: {priority_dist.get('LOW', 0)}ê°œ")
    print()

    print("ğŸ“‹ ê·œì œ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ):")
    print()

    # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬
    regulations = final_output.get('regulations', [])
    priority_order = {"HIGH": 1, "MEDIUM": 2, "LOW": 3}
    sorted_regulations = sorted(
        regulations,
        key=lambda x: priority_order.get(x['priority'], 2)
    )

    for reg in sorted_regulations:
        priority_emoji = {
            "HIGH": "ğŸ”´",
            "MEDIUM": "ğŸŸ¡",
            "LOW": "ğŸŸ¢"
        }
        emoji = priority_emoji.get(reg['priority'], "âšª")

        print(f"{emoji} [{reg['priority']}] {reg['name']}")
        print(f"   ì¹´í…Œê³ ë¦¬: {reg['category']}")
        print(f"   ê´€í• : {reg['authority']}")
        print(f"   ì ìš© ì´ìœ : {reg['why_applicable']}")
        print(f"   ì£¼ìš” ìš”êµ¬ì‚¬í•­:")
        for req in reg['key_requirements']:
            print(f"      - {req}")
        if reg['reference_url']:
            print(f"   ì°¸ê³ : {reg['reference_url']}")
        if reg.get('sources'):
            print("   ê·¼ê±°:")
            for src in reg['sources'][:3]:
                title = src.get("title") or src.get("url", "")
                url = src.get("url", "")
                print(f"      - {title} ({url})")
        print()

    print()

    # ìƒˆë¡œìš´ Agent ê²°ê³¼ ì¶œë ¥
    print_checklists(result.get('checklists', []))
    print()

    print_execution_plans(result.get('execution_plans', []))
    print()

    print_risk_assessment(result.get('risk_assessment', {}))
    print()

    print_final_report(result.get('final_report', {}))
    end_time = time.time()
    print(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")

    # JSON íŒŒì¼ë¡œ ì €ì¥ (ëª¨ë“  ë°ì´í„° í¬í•¨)
    # complete_output = {
    #     "business_info": result.get('business_info', {}),
    #     "summary": {
    #         "total_regulations": final_output.get('total_count', 0),
    #         "priority_distribution": priority_dist,
    #         "total_checklist_items": len(result.get('checklists', [])),
    #         "total_execution_plans": len(result.get('execution_plans', [])),
    #         "risk_score": result.get('risk_assessment', {}).get('total_risk_score', 0.0)
    #     },
    #     "regulations": regulations,
    #     "checklists": result.get('checklists', []),
    #     "execution_plans": result.get('execution_plans', []),
    #     "risk_assessment": result.get('risk_assessment', {}),
    #     "final_report": result.get('final_report', {})
    # }

    # output_file = "regulation_analysis_result.json"
    # with open(output_file, 'w', encoding='utf-8') as f:
    #     json.dump(complete_output, f, indent=2, ensure_ascii=False)

    # print(f"ğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ '{output_file}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # print()


if __name__ == "__main__":
    main()
